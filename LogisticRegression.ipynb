{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicroprocessorX069/Handwriting-comparison/blob/master/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4cCE3IdWNU9G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lKkUpiHRUfPU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Dataset=pd.read_csv('Data_equalSamples (1).csv')\n",
        "Dataset=pd.read_csv('Data.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mXTk7GTrUiJL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def createDataset(df,train_percent, validation_percent):\n",
        "  df=df.loc[:,'Af1':'target']\n",
        "  length=df.shape[0]\n",
        "  \n",
        "  trainEnd=int(length*train_percent)\n",
        "  \n",
        "  validationEnd=trainEnd+int(length*validation_percent)\n",
        "  \n",
        "  trainData=df.iloc[0:trainEnd]\n",
        "  trainResult=trainData.loc[:,'target']\n",
        "  trainData=trainData.loc[:,'Af1':'Bf9']\n",
        "  trainResult=trainResult.reset_index(drop=True)\n",
        "  trainData=trainData.reset_index(drop=True)\n",
        "  \n",
        "  validationData=df.iloc[trainEnd:validationEnd]\n",
        "  validationResult=validationData.loc[:,'target']\n",
        "  validationData=validationData.loc[:,'Af1':'Bf9']\n",
        "  validationResult=validationResult.reset_index(drop=True)\n",
        "  validationData=validationData.reset_index(drop=True)\n",
        "  \n",
        "  testData=df.iloc[validationEnd:length]\n",
        "  testResult=testData.loc[:,'target']\n",
        "  testData=testData.loc[:,'Af1':'Bf9']\n",
        "  testResult=testResult.reset_index(drop=True)\n",
        "  testData=testData.reset_index(drop=True)\n",
        "  \n",
        "  return trainData, trainResult, validationData, validationResult, testData, testResult\n",
        "  \n",
        "def clusterIndices(no_clusters, labels_array): #numpy \n",
        "  for cluster_no in range(no_clusters):\n",
        "    \n",
        "   return np.where(labels_array == no_clusters)[0]\n",
        "\n",
        "def GenerateBigSigma(Data, MuMatrix,TrainingPercent,IsSynthetic):\n",
        "  # To calculate BigSigma as\n",
        "  #BigSigma 41 x 41\n",
        "  #Matrix of variances between input features, to calculate PhiMatrix\n",
        "    '''\n",
        "                          x(1)      x(2)      x(3) .  .  .     x(41)\n",
        "    BigSigma =   x(1)  Var(1,1)      0         0                 0\n",
        "\n",
        "                 x(2)       0      Var(2,2)    0                 0\n",
        "\n",
        "                 x(3)       0       0        Var(3,3)            0\n",
        "                  .\n",
        "                  .\n",
        "                  .\n",
        "                 x(41)                                      Var(41,41)\n",
        "      '''        \n",
        "    \n",
        "    #Initializing BigSigma matrix as zeros since we just have to populate the diagonal elements\n",
        "    \n",
        "    BigSigma    = np.zeros((len(Data),len(Data))) #shape = 41,41\n",
        "    DataT       = np.transpose(Data) #len(DataT)=69k \n",
        "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01)) #math ceil return smallest integer less than X, basically converting to nearest bigger int #Len of training data set = 80% of 69k ~ 67k \n",
        "    varVect     = []\n",
        "    \n",
        "    # Calculating the variance for each input feature, based on training data. np.var return variance of an array\n",
        "    for i in range(0,len(DataT[0])):\n",
        "        vct = []\n",
        "        for j in range(0,int(TrainingLen)):\n",
        "            vct.append(Data[i][j])    \n",
        "        varVect.append(np.var(vct)) #Varianance of Data[i,;] i.e. input feature i\n",
        "    \n",
        "    #Populating BigSigma Matrix\n",
        "    for j in range(len(Data)):\n",
        "        BigSigma[j][j] = varVect[j] ## All other indices other than j,j (i.e. where i != j) would be zero since the covariance between two input features is no required.\n",
        "    if IsSynthetic == True:         # Use of isSynthetic not known yet\n",
        "        BigSigma = np.dot(3,BigSigma)\n",
        "    else:\n",
        "        BigSigma = np.dot(200,BigSigma)\n",
        "    ##print (\"BigSigma Generated..\")\n",
        "    return BigSigma\n",
        "\n",
        "def GetScalar(DataRow,MuRow, BigSigInv):  \n",
        "    #Converts the matrices' (x-Mu), BigSigmaInverse, (x-Mu) product to scalar\n",
        "    \n",
        "    #R is (x-Mu); Shape : 1 x 41\n",
        "    R = np.subtract(DataRow,MuRow)\n",
        "    #np.transpose(R) is Transpose of (x-Mu); Shape :  41 x 1\n",
        "    # Shape of BigSigInv is 41 x 41\n",
        "    # Therefore Shape of T i.e. (R x BigSigmaInverse x Inv(R)): (41) x 41) . (41 x 1)\n",
        "    #                                                          : 41 x 1 \n",
        "    T = np.dot(BigSigInv,np.transpose(R))  \n",
        "    L = np.dot(R,T) #(R . T)\n",
        "    # Therefore Shape of T i.e. (R x BigSigmaInverse x Inv(R)): (1 x 41). (41) x 41) . (41 x 1)\n",
        "    #                                                          : 1 x 1 # HenceScalaar\n",
        "    return L\n",
        "\n",
        "def GetRadialBasisOut(DataRow,MuRow, BigSigInv):  \n",
        "  #Calculation of Phi(x)\n",
        "  #Vector Phi(x) = (-0.5 . (x-Mu) . BigSigmaInverse . (x-Mu))\n",
        "   #              e\n",
        "    # math.exp is exponential function e^(x) where x is the argument of the function\n",
        "    phi_x = math.exp(-0.5*GetScalar(DataRow,MuRow,BigSigInv))\n",
        "    return phi_x\n",
        "\n",
        "def GetPhiMatrix(Data, MuMatrix, BigSigma, TrainingPercent = 80):\n",
        "    #Phi Matrix Shape:  No. of basis fns x Dataset_height i.e. 10 x 67k\n",
        "    # 10 Basis function matrix applied on 41 input feautres\n",
        "    '''\n",
        "    #Phi(x(1)(1/10)) Means Basis function of 1/10 th part of input feature 1 (We divided the input features with kmeans below into 10 clusters)\n",
        "    \n",
        "    Vector Phi(x) = (-0.5 . (x-Mu) . BigSigmaInverse . (x-Mu))\n",
        "                   e\n",
        "                   \n",
        "                   \n",
        "                        Phi1                   Phi2                     Phi3                    .  .  .     Phi10    # no of basis functions i.e. 10\n",
        "  PhiMatrix=   x(1)   Phi(x(1)(1/10))      Phi(x(1)(2/10))         Phi(x(1)(3/10))     .  .  .        Phi(x(1)(10/10))\n",
        "  \n",
        "               x(2)   Phi(x(2)(1/10))      Phi(x(2)(2/10))         Phi(x(2)(3/10))     .  .  .        Phi(x(2)(10/10))\n",
        "    \n",
        "               x(3)   Phi(x(3)(1/10))      Phi(x(3)(2/10))         Phi(x(3)(3/10))     .  .  .        Phi(x(3)(10/10))\n",
        "                .\n",
        "                .\n",
        "                .\n",
        "              x(67k)  Phi(x(67k)(1/10))    Phi(x(67k)(2/10))       Phi(x(67k)(3/10))     .  .  .      Phi(x(67k)(1/10))\n",
        "    '''        \n",
        "    DataT = np.transpose(Data)\n",
        "    TrainingLen = math.ceil(len(DataT)*(TrainingPercent*0.01))         \n",
        "    PHI = np.zeros((int(TrainingLen),len(MuMatrix))) \n",
        "    \n",
        "    # Calculating inverse of BigSigma matrix for the formula of phi\n",
        "    BigSigInv = np.linalg.pinv(BigSigma)\n",
        "    for  C in range(0,len(MuMatrix)):\n",
        "        for R in range(0,int(TrainingLen)):\n",
        "            #Calculating Phi of each x1\n",
        "            PHI[R][C] = GetRadialBasisOut(DataT[R], MuMatrix[C], BigSigInv)\n",
        "    #print (\"PHI Generated..\")\n",
        "    return PHI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uvlL67mVbVPo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "72149d15-a384-4912-e789-cd9d8f872a63"
      },
      "cell_type": "code",
      "source": [
        "validation_percent=0\n",
        "train_percent=0.7\n",
        "m=8\n",
        "IsSynthetic=False\n",
        "trainData, trainResult, validationData, validationResult, testData, testResult = createDataset(Dataset,train_percent, validation_percent)\n",
        "\n",
        "trainData=np.array(trainData)\n",
        "trainResult=np.array(trainResult)\n",
        "testData=np.array(testData)\n",
        "testResult=np.array(testResult)\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "trainTranspose=np.transpose(trainData)\n",
        "kmeans=KMeans(m,random_state=0).fit(trainData)\n",
        "means=np.array(kmeans.cluster_centers_)\n",
        "variance_mat     = GenerateBigSigma(trainTranspose, means,100 ,IsSynthetic) # generating variance for each input feature\n",
        "train_phi = GetPhiMatrix(trainTranspose, means, variance_mat, 100)\n",
        "print(train_phi.shape)\n",
        "\n",
        "testTranspose=np.transpose(testData)\n",
        "kmeans=KMeans(m,random_state=0).fit(testData)\n",
        "means=np.array(kmeans.cluster_centers_)\n",
        "#ClusterIndicesNumpy(7, kmeans.labels_)\n",
        "variance_mat     = GenerateBigSigma(testTranspose, means,100 ,IsSynthetic) # generating variance for each input feature\n",
        "test_phi = GetPhiMatrix(testTranspose, means, variance_mat, 100)\n",
        "print(test_phi.shape)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(205676, 8)\n",
            "(88147, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NJmqIaKycnpM",
        "colab_type": "code",
        "outputId": "db794e27-3a71-42a5-c29e-c038d6a4985c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(grad_descent(train_phi,trainResult,test_phi,testResult,batch_size=2000,learning_rate=0.1))\n",
        "plt.show()"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFKCAYAAAAqkecjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFfL/AUHwtACQV432AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f8b5ba359e8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "qNp1q1OzEEDp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logisticReg(train_phi,trainResult,test_phi,testResult,0.2,5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7mlbonkRZZE1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + math.exp(-x))\n",
        "\n",
        "def logisticReg(trainData,trainResult,testData,testResult,learning_rate=0.2,no_epochs=5):\n",
        "  W=np.zeros(trainData.shape[1])\n",
        "  j=-1\n",
        "  for epoch in range(0,no_epochs):\n",
        "    #print(\"epoch no:\", epoch)\n",
        "    j=-1\n",
        "    for input in trainData:\n",
        "      output=W[0]\n",
        "      j=j+1\n",
        "\n",
        "      for i in range(1,len(W)):\n",
        "        output=output+W[i]*input[i-1]\n",
        "      target=trainResult[j]\n",
        "      output=sigmoid(output)\n",
        "      for i in range(0,len(W)):  \n",
        "        if(i==0):\n",
        "          weight_change=learning_rate*(target-output)*output*(1-output)\n",
        "          W[i]=W[i]+weight_change\n",
        "        else:\n",
        "          weight_change=learning_rate*(target-output)*output*(1-output)*input[i-1]\n",
        "          W[i]=W[i]+weight_change\n",
        "      print(\"updated weight times:\",epoch, j)\n",
        "  correct=0\n",
        "  j=-1\n",
        "  for input in testData:\n",
        "    output=W[0]\n",
        "    j=j+1\n",
        "    for i in range(1,len(W)):\n",
        "      output=output+W[i]*input[i-1]\n",
        "    target=testResult[j]\n",
        "    output=round(sigmoid(output),0)\n",
        "    if(target==output):\n",
        "      correct=correct+1\n",
        "  print((correct*100)/j)\n",
        "  \n",
        "def getOutput(input_data, weights):\n",
        "  predicted_result=[]\n",
        "  for input in input_data:\n",
        "      output=0\n",
        "      for i in range(1,len(W)):\n",
        "        output=output+weights[i]*input[i-1]\n",
        "      output=sigmoid(output)\n",
        "      predicted_result.append(output)\n",
        "  return(np.array(predicted_result))\n",
        "\n",
        "def updateWeights(input_data,target_result,predicted_result,prev_weights,learning_rate):\n",
        "  subtract=np.subtract(predicted_result,target_result)\n",
        "  weight_change=np.dot(subtract,input_data)\n",
        "  weight_change/=(input_data.shape[1])\n",
        "  weight_change*=learning_rate\n",
        "  new_weights=np.subtract(prev_weights,weight_change)\n",
        "  return new_weights\n",
        "\n",
        "def loss(target_result,predicted_result):\n",
        "  loss=-target_result*np.log(predicted_result)-(1-target_result)*np.log(1-predicted_result)\n",
        "  loss=loss.sum()/target_result.shape[0]\n",
        "  return loss\n",
        "  \n",
        "     \n",
        "   \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JL_Nr-v5pjYj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def grad_descent(train_phi,trainResult,validation_phi,validationResult,batch_size=5000,learning_rate=0.2):\n",
        "  W=np.zeros(train_phi.shape[1])\n",
        "  i=0\n",
        "  loss_arr=[]\n",
        "  while i+batch_size <= train_phi.shape[0]:\n",
        "    input_data=train_phi[i:i+batch_size]\n",
        "    target_result=trainResult[i:i+batch_size]\n",
        "    i=i+batch_size\n",
        "    new_lr=learning_rate-(1/i)\n",
        "    if(new_lr<=0):\n",
        "      new_lr=learning_rate\n",
        "    predicted_result=getOutput(input_data,W)\n",
        "    validation_predictedResult=getOutput(validation_phi,W)\n",
        "    W=updateWeights(input_data,target_result,predicted_result,W,learning_rate)\n",
        "    loss_arr.append(loss(validationResult,validation_predictedResult))\n",
        "  return(loss_arr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}